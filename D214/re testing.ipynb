{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a0792c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\M'\n",
      "C:\\Users\\charlesrowe\\AppData\\Local\\Temp\\ipykernel_21464\\1295670377.py:4: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  directory = os.chdir(\"G:\\My Drive\\Capstone Files\\Datasets\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "directory = os.chdir(\"G:\\My Drive\\Capstone Files\\Datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e38ca31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\charlesrowe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\charlesrowe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\charlesrowe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\charlesrowe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"cleaned_full_df_with_census_regions.csv\")\n",
    "\n",
    "cols_to_drop = df[(df['census region'] == 'northeast') | (df['census region'] == 'midwest')].index\n",
    "df.drop(cols_to_drop, inplace=True)\n",
    "\n",
    "import demoji\n",
    "import re\n",
    "\n",
    "def remove_emoji(string):\n",
    "    return demoji.replace(string, '')\n",
    "\n",
    "def remove_extra_spaces(string):\n",
    "    return re.sub(r'\\s{2,}',' ',str(string))\n",
    "\n",
    "df['cleaned text'] = df['Review Text'].apply(remove_emoji)\n",
    "df['cleaned text'] = df['cleaned text'].apply(remove_extra_spaces)\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "import unicodedata\n",
    "import nltk.corpus\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "    stops = nltk.corpus.stopwords.words('english') + list(string.punctuation) + ['...',' - ', 'ca', 'wo', \"'s\", \"'ing\",\"'ll\", \"'re\"]\n",
    "    negation = ['but', 'not', \"don't\", \"aren't\", \"couldn't\", \"doesn't\", \"hadn't\", \"hasn't\", \"haven't\", \n",
    "                  \"isn't\", \"shouldn't\", \"wouldn't\"]\n",
    "    for word in negation:\n",
    "        stops.remove(word)\n",
    "    sentence = (unicodedata.normalize('NFKD', sentence)\n",
    "        .encode('ascii', 'ignore')\n",
    "        .decode('utf-8', 'ignore')\n",
    "        .lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', sentence).split()\n",
    "    word_list = [word for word in words if word not in stops]\n",
    "    return word_list\n",
    "\n",
    "def get_words(df, column):\n",
    "    return clean_sentence(''.join(str(df[column].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3de24c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charlesrowe\\AppData\\Local\\Temp\\ipykernel_21464\\3838607419.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  south_df['cleaned text'] = south_df['cleaned text'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "mask = df['census region'] == 'southern'\n",
    "south_df = df[mask]\n",
    "west_df = df[~mask]\n",
    "\n",
    "south_df['cleaned text'] = south_df['cleaned text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ae001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charlesrowe\\AppData\\Local\\Temp\\ipykernel_21464\\2853981048.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['context'] = [re.search(pattern,i) for i in start_context]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11        <re.Match object; span=(229, 255), match='clea...\n",
       "94        <re.Match object; span=(53, 80), match='clearl...\n",
       "190       <re.Match object; span=(363, 395), match='clea...\n",
       "250       <re.Match object; span=(135, 142), match='clea...\n",
       "261       <re.Match object; span=(50, 70), match='clearl...\n",
       "                                ...                        \n",
       "198134    <re.Match object; span=(0, 19), match='clearly...\n",
       "198237    <re.Match object; span=(242, 266), match='clea...\n",
       "198440    <re.Match object; span=(267, 295), match='clea...\n",
       "198472    <re.Match object; span=(549, 570), match='clea...\n",
       "198531    <re.Match object; span=(569, 589), match='clea...\n",
       "Name: context, Length: 940, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def context(pattern, dataframe):\n",
    "    start_context = pd.Series(dataframe['cleaned text'])\n",
    "    dataframe['context'] = [re.search(pattern,i) for i in start_context]\n",
    "    context_df = dataframe.dropna(subset=['context'])\n",
    "    return context_df['context']\n",
    "\n",
    "context(r'(\\w+\\s+){0,3}clearly(\\s+\\S+){0,3}',south_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5d4b4f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(29, 58), match='clearly not working correctly'>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"love top you for why is this clearly not working correctly and I can't work\"\n",
    "\n",
    "re.search(r'clearly(\\s+\\S+){0,3}',text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
