{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "08d2a94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsgam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\hsgam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsgam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Embedding, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "tf.config.run_functions_eagerly(True)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8b1d2e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       A very, very, very slow-moving, aimless movie ...\n",
      "1       Not sure who was more lost - the flat characte...\n",
      "2       Attempting artiness with black & white and cle...\n",
      "3            Very little music or anything to speak of.  \n",
      "4       The best scene in the movie was when Gerardo i...\n",
      "                              ...                        \n",
      "2995    I think food should have flavor and texture an...\n",
      "2996                             Appetite instantly gone.\n",
      "2997    Overall I was not impressed and would not go b...\n",
      "2998    The whole experience was underwhelming, and I ...\n",
      "2999    Then, as if I hadn't wasted enough of my life ...\n",
      "Name: review, Length: 3000, dtype: object\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "2995    0\n",
      "2996    0\n",
      "2997    0\n",
      "2998    0\n",
      "2999    0\n",
      "Name: label, Length: 3000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "imdb_db_full = pd.read_csv('imdb_labelled.txt', sep='\\t')\n",
    "amazon_db_full = pd.read_csv('amazon_cells_labelled.txt', sep='\\t')\n",
    "yelp_db_full = pd.read_csv('yelp_labelled.txt', sep='\\t')\n",
    "\n",
    "imdb_db_full.to_csv('imdb.csv')\n",
    "full_db = pd.concat((imdb_db_full,amazon_db_full,yelp_db_full), ignore_index=True)\n",
    "full_db.to_csv('full_db.csv')\n",
    "n_cols = full_db.shape[1]\n",
    "\n",
    "reviews = full_db.iloc[:,0]\n",
    "labels = full_db.iloc[:,1]\n",
    "\n",
    "print(reviews)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f8cf18bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3000 reviews.\n",
      "There are 3000 reviews.\n"
     ]
    }
   ],
   "source": [
    "review_text = np.asarray(reviews)\n",
    "print(f\"There are {len(review_text)} reviews.\")\n",
    "review_text = review_text[~pd.isnull(review_text)]\n",
    "print(f\"There are {len(review_text)} reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2b2dadaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3000 labels.\n",
      "There are 3000 labels.\n"
     ]
    }
   ],
   "source": [
    "rev_labels = np.asarray(labels)\n",
    "print(f\"There are {len(rev_labels)} labels.\")\n",
    "rev_labels = rev_labels[~pd.isnull(rev_labels)]\n",
    "print(f\"There are {len(rev_labels)} labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4c18fdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized into 3000 elements.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a very, very, very slow-moving, aimless movie about a distressed, drifting young man.']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokens = [sent_tokenize(review.lower()) for review in review_text]\n",
    "print(f'Tokenized into {len(sentence_tokens)} elements.')\n",
    "sentence_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "528c6399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238 stopwords\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\",\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '...',\n",
       " ' - ',\n",
       " 'ca',\n",
       " 'wo',\n",
       " \"'s\",\n",
       " \"'ing\",\n",
       " \"'ll\",\n",
       " \"'re\"]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops = stopwords.words('english') + list(string.punctuation) + ['...',' - ', 'ca', 'wo', \"'s\", \"'ing\",\"'ll\", \"'re\"]\n",
    "print(f\"{len(stops)} stopwords\")\n",
    "stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e39ac863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 stopwords\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " 'has',\n",
       " 'hasn',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\",\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '...',\n",
       " ' - ',\n",
       " 'ca',\n",
       " 'wo',\n",
       " \"'s\",\n",
       " \"'ing\",\n",
       " \"'ll\",\n",
       " \"'re\"]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negation = ['but', 'not', \"don't\", \"aren't\", \"couldn't\", \"doesn't\", \"hadn't\", \"hasn't\", \"haven't\", \n",
    "                  \"isn't\", \"shouldn't\", \"wouldn't\"]\n",
    "for word in negation:\n",
    "    stops.remove(word)\n",
    "print(f\"{len(stops)} stopwords\")\n",
    "stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a70884dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens = []\n",
    "\n",
    "for sentences in sentence_tokens:\n",
    "    temporary_list = []\n",
    "\n",
    "    if (len(sentences)) == 1:\n",
    "        words_in_sentence = word_tokenize(sentences[0])\n",
    "        for word in words_in_sentence:\n",
    "            if word == \"n't\":\n",
    "                word = \"not\"\n",
    "            temporary_list.append(word)\n",
    "    else:\n",
    "        num_sentences = len(sentences)\n",
    "\n",
    "        for i in range(0, num_sentences):\n",
    "            words_in_sentence = word_tokenize(sentences[i])\n",
    "            for word in words_in_sentence:\n",
    "                if word == \"n't\":\n",
    "                    word = \"not\"\n",
    "                temporary_list.append(word)\n",
    "\n",
    "    if len(temporary_list) == 0:\n",
    "        temporary_list = ['empty']\n",
    "\n",
    "    trimmed_words = [word for word in temporary_list if word not in stops]\n",
    "    word_tokens.append(trimmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fe9c2756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New maximum review length found: Index 0 contains 7 word tokens.\n",
      "New maximum review length found: Index 1 contains 9 word tokens.\n",
      "New maximum review length found: Index 2 contains 18 word tokens.\n",
      "New maximum review length found: Index 42 contains 25 word tokens.\n",
      "New maximum review length found: Index 243 contains 27 word tokens.\n",
      "New maximum review length found: Index 390 contains 39 word tokens.\n",
      "New maximum review length found: Index 620 contains 41 word tokens.\n",
      "There are 19309 words in this dataset, of which 5206 words are unique. \n",
      "The maximum number of words in any single review is 41.\n"
     ]
    }
   ],
   "source": [
    "i = 0 \n",
    "bag_of_words = []\n",
    "max_review_length = 0\n",
    "\n",
    "for words in word_tokens:\n",
    "    if len(words) > max_review_length:\n",
    "        max_review_length = len(words)\n",
    "        print(f\"New maximum review length found: Index {i} contains {max_review_length} word tokens.\")\n",
    "    for word in words:\n",
    "        bag_of_words.append(word)\n",
    "    i += 1 \n",
    "\n",
    "unique_words = set(bag_of_words)\n",
    "num_uniq_words = len(unique_words)\n",
    "print(f\"There are {len(bag_of_words)} words in this dataset, of which {num_uniq_words} words are unique. \\nThe maximum number of words in any single review is {max_review_length}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "45b52b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['masterful',\n",
       " 'piece',\n",
       " 'film-making',\n",
       " 'many',\n",
       " 'themes',\n",
       " 'simmering',\n",
       " 'occasionally',\n",
       " 'boiling',\n",
       " 'warts',\n",
       " 'study',\n",
       " 'poet',\n",
       " 'bohemian',\n",
       " 'self-indulgent',\n",
       " 'wartime',\n",
       " 'years',\n",
       " 'span',\n",
       " 'aerial',\n",
       " 'bombardments',\n",
       " 'london',\n",
       " 'outward',\n",
       " 'tranquillity',\n",
       " 'welsh',\n",
       " 'coastal',\n",
       " 'retreat',\n",
       " 'borderlines',\n",
       " 'friendship',\n",
       " 'lust',\n",
       " 'love',\n",
       " 'dedication',\n",
       " 'art',\n",
       " 'experience',\n",
       " 'versus',\n",
       " 'practical',\n",
       " 'concerns',\n",
       " 'jealousy',\n",
       " 'rivalry',\n",
       " 'cowardice',\n",
       " 'egotism',\n",
       " 'versus',\n",
       " 'heroism',\n",
       " 'self-sacrifice']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens[620]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c82e399a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommended</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>slow-moving aimless movie distressed drifting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>not sure lost flat characters audience nearly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>attempting artiness black white clever camera ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>little music anything speak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>best scene movie gerardo trying find song keep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0</td>\n",
       "      <td>think food flavor texture lacking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0</td>\n",
       "      <td>appetite instantly gone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0</td>\n",
       "      <td>overall not impressed would not go back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0</td>\n",
       "      <td>whole experience underwhelming think go ninja ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0</td>\n",
       "      <td>not wasted enough life poured salt wound drawi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      recommended                                        review_text\n",
       "0               0  slow-moving aimless movie distressed drifting ...\n",
       "1               0  not sure lost flat characters audience nearly ...\n",
       "2               0  attempting artiness black white clever camera ...\n",
       "3               0                       little music anything speak \n",
       "4               1  best scene movie gerardo trying find song keep...\n",
       "...           ...                                                ...\n",
       "2995            0                 think food flavor texture lacking \n",
       "2996            0                           appetite instantly gone \n",
       "2997            0           overall not impressed would not go back \n",
       "2998            0  whole experience underwhelming think go ninja ...\n",
       "2999            0  not wasted enough life poured salt wound drawi...\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_list = []\n",
    "i = 0\n",
    "# Iterate through each index across the cleaned up word_tokens\n",
    "for i in range(0, len(word_tokens)):\n",
    "    # Generate a temporary dictionary and a temporary string\n",
    "    temp_dict = {}\n",
    "    temp_string = \"\"\n",
    "    # Take each word out of the indexed word_tokens (instead of taking the entire list at that index) and add it to temp_string\n",
    "    for word in word_tokens[i]:\n",
    "        temp_string = temp_string + word + \" \"\n",
    "    # Update dictionary with the appropriate key-value pairs (the columns we want and the values we want)\n",
    "    temp_dict.update({\"recommended\" : rev_labels[i]})\n",
    "    temp_dict.update({\"review_text\" : temp_string})\n",
    "    # Add the temporary dictionary to the list of dictionaries\n",
    "    row_list.append(temp_dict)\n",
    "    # Iterate the counter\n",
    "    i += 1\n",
    "# Use the list of dictionaries to quickly build a dataframe\n",
    "new_df = pd.DataFrame(row_list)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f3ef6555",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df['review_text']\n",
    "y = new_df['recommended']\n",
    "\n",
    "X_train, X_remaining, y_train, y_remaining = train_test_split(X, y, train_size=.7, random_state = 1987)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_remaining, y_remaining, test_size=0.5, random_state = 1987) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "44989b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab is 4095 elements long.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'not': 1,\n",
       " 'good': 2,\n",
       " 'great': 3,\n",
       " 'but': 4,\n",
       " 'movie': 5,\n",
       " 'phone': 6,\n",
       " 'film': 7,\n",
       " 'one': 8,\n",
       " 'food': 9,\n",
       " 'like': 10,\n",
       " 'time': 11,\n",
       " 'service': 12,\n",
       " 'really': 13,\n",
       " 'bad': 14,\n",
       " 'well': 15,\n",
       " 'would': 16,\n",
       " 'place': 17,\n",
       " 'could': 18,\n",
       " 'best': 19,\n",
       " 'ever': 20,\n",
       " 'go': 21,\n",
       " 'back': 22,\n",
       " 'even': 23,\n",
       " 'also': 24,\n",
       " 'quality': 25,\n",
       " 'made': 26,\n",
       " 'product': 27,\n",
       " \"''\": 28,\n",
       " 'work': 29,\n",
       " 'nice': 30,\n",
       " \"'m\": 31,\n",
       " 'love': 32,\n",
       " \"'ve\": 33,\n",
       " 'get': 34,\n",
       " 'works': 35,\n",
       " 'excellent': 36,\n",
       " 'recommend': 37,\n",
       " 'think': 38,\n",
       " 'better': 39,\n",
       " 'first': 40,\n",
       " 'see': 41,\n",
       " 'sound': 42,\n",
       " 'battery': 43,\n",
       " 'got': 44,\n",
       " 'never': 45,\n",
       " 'still': 46,\n",
       " '10': 47,\n",
       " 'much': 48,\n",
       " 'way': 49,\n",
       " 'acting': 50,\n",
       " 'headset': 51,\n",
       " 'use': 52,\n",
       " 'pretty': 53,\n",
       " 'say': 54,\n",
       " 'worst': 55,\n",
       " 'terrible': 56,\n",
       " 'right': 57,\n",
       " 'thing': 58,\n",
       " 'price': 59,\n",
       " 'make': 60,\n",
       " 'amazing': 61,\n",
       " 'disappointed': 62,\n",
       " 'every': 63,\n",
       " 'real': 64,\n",
       " 'two': 65,\n",
       " 'minutes': 66,\n",
       " 'little': 67,\n",
       " 'everything': 68,\n",
       " 'many': 69,\n",
       " 'look': 70,\n",
       " 'money': 71,\n",
       " 'nothing': 72,\n",
       " '2': 73,\n",
       " 'experience': 74,\n",
       " 'lot': 75,\n",
       " 'poor': 76,\n",
       " 'story': 77,\n",
       " 'know': 78,\n",
       " 'happy': 79,\n",
       " 'awful': 80,\n",
       " 'enough': 81,\n",
       " 'going': 82,\n",
       " 'quite': 83,\n",
       " 'definitely': 84,\n",
       " 'waste': 85,\n",
       " 'people': 86,\n",
       " 'used': 87,\n",
       " \"'d\": 88,\n",
       " 'plot': 89,\n",
       " 'characters': 90,\n",
       " 'ear': 91,\n",
       " 'screen': 92,\n",
       " 'friendly': 93,\n",
       " 'fine': 94,\n",
       " 'wonderful': 95,\n",
       " 'case': 96,\n",
       " 'years': 97,\n",
       " 'movies': 98,\n",
       " 'highly': 99,\n",
       " 'new': 100,\n",
       " 'script': 101,\n",
       " 'show': 102,\n",
       " 'big': 103,\n",
       " 'went': 104,\n",
       " 'films': 105,\n",
       " 'watching': 106,\n",
       " 'life': 107,\n",
       " 'anyone': 108,\n",
       " '1': 109,\n",
       " 'comfortable': 110,\n",
       " 'far': 111,\n",
       " 'bought': 112,\n",
       " 'times': 113,\n",
       " 'eat': 114,\n",
       " 'cool': 115,\n",
       " 'funny': 116,\n",
       " 'another': 117,\n",
       " 'however': 118,\n",
       " 'around': 119,\n",
       " 'found': 120,\n",
       " 'worth': 121,\n",
       " 'take': 122,\n",
       " 'restaurant': 123,\n",
       " 'always': 124,\n",
       " 'staff': 125,\n",
       " 'day': 126,\n",
       " 'came': 127,\n",
       " 'scenes': 128,\n",
       " 'horrible': 129,\n",
       " 'come': 130,\n",
       " 'small': 131,\n",
       " 'totally': 132,\n",
       " 'music': 133,\n",
       " 'car': 134,\n",
       " 'part': 135,\n",
       " 'night': 136,\n",
       " 'long': 137,\n",
       " 'piece': 138,\n",
       " 'since': 139,\n",
       " 'cast': 140,\n",
       " 'end': 141,\n",
       " 'want': 142,\n",
       " 'stars': 143,\n",
       " 'black': 144,\n",
       " 'easy': 145,\n",
       " 'loved': 146,\n",
       " 'delicious': 147,\n",
       " 'buy': 148,\n",
       " 'worked': 149,\n",
       " 'job': 150,\n",
       " 'said': 151,\n",
       " 'overall': 152,\n",
       " 'chicken': 153,\n",
       " 'perfect': 154,\n",
       " 'fresh': 155,\n",
       " 'vegas': 156,\n",
       " 'actually': 157,\n",
       " 'actors': 158,\n",
       " 'must': 159,\n",
       " 'us': 160,\n",
       " 'probably': 161,\n",
       " 'line': 162,\n",
       " 'fantastic': 163,\n",
       " 'customer': 164,\n",
       " 'camera': 165,\n",
       " 'slow': 166,\n",
       " 'seen': 167,\n",
       " 'anything': 168,\n",
       " 'last': 169,\n",
       " 'fast': 170,\n",
       " 'beautiful': 171,\n",
       " 'character': 172,\n",
       " 'server': 173,\n",
       " '3': 174,\n",
       " 'family': 175,\n",
       " 'reception': 176,\n",
       " 'left': 177,\n",
       " 'hard': 178,\n",
       " 'absolutely': 179,\n",
       " 'motorola': 180,\n",
       " 'worse': 181,\n",
       " 'things': 182,\n",
       " 'awesome': 183,\n",
       " 'sucks': 184,\n",
       " 'give': 185,\n",
       " 'makes': 186,\n",
       " 'charger': 187,\n",
       " 'done': 188,\n",
       " 'bland': 189,\n",
       " 'cheap': 190,\n",
       " 'away': 191,\n",
       " 'full': 192,\n",
       " 'ordered': 193,\n",
       " 'taste': 194,\n",
       " 'talk': 195,\n",
       " 'either': 196,\n",
       " 'sucked': 197,\n",
       " 'impressed': 198,\n",
       " 'thought': 199,\n",
       " 'hour': 200,\n",
       " 'completely': 201,\n",
       " 'call': 202,\n",
       " 'interesting': 203,\n",
       " 'mediocre': 204,\n",
       " 'may': 205,\n",
       " 'tried': 206,\n",
       " 'cell': 207,\n",
       " 'getting': 208,\n",
       " 'burger': 209,\n",
       " 'crap': 210,\n",
       " 'find': 211,\n",
       " 'order': 212,\n",
       " 'watch': 213,\n",
       " 'bluetooth': 214,\n",
       " 'fit': 215,\n",
       " 'problems': 216,\n",
       " 'hear': 217,\n",
       " 'purchase': 218,\n",
       " 'salad': 219,\n",
       " 'coming': 220,\n",
       " 'performance': 221,\n",
       " '5': 222,\n",
       " 'rather': 223,\n",
       " 'disappointment': 224,\n",
       " 'return': 225,\n",
       " 'though': 226,\n",
       " 'truly': 227,\n",
       " 'enjoyed': 228,\n",
       " 'sauce': 229,\n",
       " 'seriously': 230,\n",
       " 'flavor': 231,\n",
       " 'expect': 232,\n",
       " 'easily': 233,\n",
       " 'pizza': 234,\n",
       " 'steak': 235,\n",
       " 'scene': 236,\n",
       " 'everyone': 237,\n",
       " 'atmosphere': 238,\n",
       " 'especially': 239,\n",
       " 'menu': 240,\n",
       " 'feeling': 241,\n",
       " 'volume': 242,\n",
       " 'kind': 243,\n",
       " 'tell': 244,\n",
       " 'device': 245,\n",
       " 'avoid': 246,\n",
       " 'extremely': 247,\n",
       " 'several': 248,\n",
       " 'fact': 249,\n",
       " 'mess': 250,\n",
       " 'art': 251,\n",
       " 'special': 252,\n",
       " 'wait': 253,\n",
       " 'almost': 254,\n",
       " 'perfectly': 255,\n",
       " 'felt': 256,\n",
       " 'cold': 257,\n",
       " 'incredible': 258,\n",
       " 'glad': 259,\n",
       " 'certainly': 260,\n",
       " 'put': 261,\n",
       " 'disappointing': 262,\n",
       " 'simply': 263,\n",
       " 'sure': 264,\n",
       " 'different': 265,\n",
       " 'super': 266,\n",
       " 'priced': 267,\n",
       " 'using': 268,\n",
       " 'decent': 269,\n",
       " 'problem': 270,\n",
       " 'enjoy': 271,\n",
       " 'clear': 272,\n",
       " 'play': 273,\n",
       " 'gets': 274,\n",
       " 'gave': 275,\n",
       " 'least': 276,\n",
       " 'need': 277,\n",
       " 'next': 278,\n",
       " 'sushi': 279,\n",
       " 'none': 280,\n",
       " 'second': 281,\n",
       " 'amazon': 282,\n",
       " 'whole': 283,\n",
       " 'plug': 284,\n",
       " 'phones': 285,\n",
       " 'hands': 286,\n",
       " 'area': 287,\n",
       " 'stupid': 288,\n",
       " 'low': 289,\n",
       " 'i': 290,\n",
       " 'let': 291,\n",
       " 'effects': 292,\n",
       " 'looks': 293,\n",
       " '20': 294,\n",
       " 'feel': 295,\n",
       " 'told': 296,\n",
       " 'perhaps': 297,\n",
       " 'deal': 298,\n",
       " 'less': 299,\n",
       " 'cinematography': 300,\n",
       " 'face': 301,\n",
       " 'kids': 302,\n",
       " 'suspense': 303,\n",
       " 'bar': 304,\n",
       " 'started': 305,\n",
       " 'ending': 306,\n",
       " 'white': 307,\n",
       " 'working': 308,\n",
       " 'saw': 309,\n",
       " 'writing': 310,\n",
       " 'charge': 311,\n",
       " 'voice': 312,\n",
       " 'watched': 313,\n",
       " 'unit': 314,\n",
       " 'together': 315,\n",
       " 'believe': 316,\n",
       " 'meat': 317,\n",
       " 'something': 318,\n",
       " 'keep': 319,\n",
       " 'high': 320,\n",
       " 'man': 321,\n",
       " 'unfortunately': 322,\n",
       " 'wrong': 323,\n",
       " 'fun': 324,\n",
       " 'dishes': 325,\n",
       " 'item': 326,\n",
       " 'dialogue': 327,\n",
       " 'waited': 328,\n",
       " 'attentive': 329,\n",
       " 'action': 330,\n",
       " 'mind': 331,\n",
       " 'obviously': 332,\n",
       " 'design': 333,\n",
       " 'solid': 334,\n",
       " 'game': 335,\n",
       " 'beer': 336,\n",
       " 'selection': 337,\n",
       " 'word': 338,\n",
       " 'audio': 339,\n",
       " 'cinema': 340,\n",
       " 'weak': 341,\n",
       " 'waiting': 342,\n",
       " '4': 343,\n",
       " 'drama': 344,\n",
       " 'broke': 345,\n",
       " 'buffet': 346,\n",
       " 'try': 347,\n",
       " 'ask': 348,\n",
       " 'fits': 349,\n",
       " 'light': 350,\n",
       " 'directing': 351,\n",
       " 'finally': 352,\n",
       " 'care': 353,\n",
       " 'calls': 354,\n",
       " 'house': 355,\n",
       " 'prices': 356,\n",
       " 'short': 357,\n",
       " 'tasty': 358,\n",
       " 'important': 359,\n",
       " 'wear': 360,\n",
       " 'stay': 361,\n",
       " 'someone': 362,\n",
       " 'fails': 363,\n",
       " 'home': 364,\n",
       " 'liked': 365,\n",
       " 'john': 366,\n",
       " 'else': 367,\n",
       " 'kept': 368,\n",
       " 'company': 369,\n",
       " 'meal': 370,\n",
       " 'soon': 371,\n",
       " 'wife': 372,\n",
       " 'year': 373,\n",
       " 'places': 374,\n",
       " 'expected': 375,\n",
       " 'human': 376,\n",
       " 'girl': 377,\n",
       " 'old': 378,\n",
       " 'received': 379,\n",
       " 'half': 380,\n",
       " 'ridiculous': 381,\n",
       " 'the': 382,\n",
       " 'playing': 383,\n",
       " 'predictable': 384,\n",
       " 'side': 385,\n",
       " 'dish': 386,\n",
       " 'eating': 387,\n",
       " 'wanted': 388,\n",
       " 'rating': 389,\n",
       " 'point': 390,\n",
       " 'sick': 391,\n",
       " 'seemed': 392,\n",
       " 'average': 393,\n",
       " 'days': 394,\n",
       " 'without': 395,\n",
       " 'pay': 396,\n",
       " 'star': 397,\n",
       " 'oh': 398,\n",
       " 'although': 399,\n",
       " 'dropped': 400,\n",
       " 'book': 401,\n",
       " 'turn': 402,\n",
       " '30': 403,\n",
       " 'wasted': 404,\n",
       " 'non': 405,\n",
       " 'charm': 406,\n",
       " 'location': 407,\n",
       " 'dont': 408,\n",
       " 'today': 409,\n",
       " 'hot': 410,\n",
       " 'horror': 411,\n",
       " 'note': 412,\n",
       " 'flick': 413,\n",
       " 'tender': 414,\n",
       " 'guess': 415,\n",
       " 'rude': 416,\n",
       " 'overpriced': 417,\n",
       " 'recommended': 418,\n",
       " 'store': 419,\n",
       " 'hours': 420,\n",
       " 'style': 421,\n",
       " 'history': 422,\n",
       " 'director': 423,\n",
       " 'bit': 424,\n",
       " 'friends': 425,\n",
       " 'software': 426,\n",
       " 'buttons': 427,\n",
       " 'portrayal': 428,\n",
       " 'huge': 429,\n",
       " 'hold': 430,\n",
       " 'top': 431,\n",
       " 'arrived': 432,\n",
       " 'warm': 433,\n",
       " 'junk': 434,\n",
       " 'close': 435,\n",
       " 'trying': 436,\n",
       " 'twice': 437,\n",
       " 'tv': 438,\n",
       " 'pleased': 439,\n",
       " 'performances': 440,\n",
       " 'sandwich': 441,\n",
       " 'whether': 442,\n",
       " 'cooked': 443,\n",
       " 'ago': 444,\n",
       " 'picture': 445,\n",
       " 'verizon': 446,\n",
       " 'three': 447,\n",
       " 'series': 448,\n",
       " 'comedy': 449,\n",
       " 'quickly': 450,\n",
       " 'lacks': 451,\n",
       " 'headphones': 452,\n",
       " 'authentic': 453,\n",
       " 'soundtrack': 454,\n",
       " 'par': 455,\n",
       " 'beyond': 456,\n",
       " 'choice': 457,\n",
       " 'lines': 458,\n",
       " 'extra': 459,\n",
       " 'features': 460,\n",
       " 'terrific': 461,\n",
       " 'bring': 462,\n",
       " 'lots': 463,\n",
       " 'couple': 464,\n",
       " 'shrimp': 465,\n",
       " 'barely': 466,\n",
       " 'pictures': 467,\n",
       " 'given': 468,\n",
       " 'looking': 469,\n",
       " 'eyes': 470,\n",
       " 'rest': 471,\n",
       " 'value': 472,\n",
       " 'possible': 473,\n",
       " 'joke': 474,\n",
       " 'reasonably': 475,\n",
       " 'town': 476,\n",
       " 'rice': 477,\n",
       " 'lunch': 478,\n",
       " 'superb': 479,\n",
       " 'fried': 480,\n",
       " 'bars': 481,\n",
       " 'water': 482,\n",
       " 'front': 483,\n",
       " 'samsung': 484,\n",
       " 'strong': 485,\n",
       " 'basically': 486,\n",
       " 'player': 487,\n",
       " 'management': 488,\n",
       " 'sometimes': 489,\n",
       " 'brilliant': 490,\n",
       " '8': 491,\n",
       " 'maybe': 492,\n",
       " 'reasonable': 493,\n",
       " 'party': 494,\n",
       " 'loud': 495,\n",
       " 'hope': 496,\n",
       " 'razr': 497,\n",
       " 'hate': 498,\n",
       " 'entire': 499,\n",
       " 'costs': 500,\n",
       " 'simple': 501,\n",
       " 'plus': 502,\n",
       " 'budget': 503,\n",
       " 'running': 504,\n",
       " 'needed': 505,\n",
       " 'yet': 506,\n",
       " 'spot': 507,\n",
       " 'reading': 508,\n",
       " 'breakfast': 509,\n",
       " 'world': 510,\n",
       " 'played': 511,\n",
       " 'ears': 512,\n",
       " 'beef': 513,\n",
       " 'list': 514,\n",
       " 'week': 515,\n",
       " 'cases': 516,\n",
       " 'inside': 517,\n",
       " 'owner': 518,\n",
       " 'dead': 519,\n",
       " 'took': 520,\n",
       " 'ok': 521,\n",
       " 'room': 522,\n",
       " 'setting': 523,\n",
       " 'satisfied': 524,\n",
       " 'believable': 525,\n",
       " 'generally': 526,\n",
       " 'tasted': 527,\n",
       " 'gives': 528,\n",
       " 'seems': 529,\n",
       " 'quick': 530,\n",
       " 'check': 531,\n",
       " 'tasteless': 532,\n",
       " 'set': 533,\n",
       " 'roles': 534,\n",
       " 'subtle': 535,\n",
       " 'served': 536,\n",
       " 'difficult': 537,\n",
       " 'range': 538,\n",
       " 'might': 539,\n",
       " 'fan': 540,\n",
       " 'adorable': 541,\n",
       " 'waitress': 542,\n",
       " 'whatever': 543,\n",
       " 'free': 544,\n",
       " 'months': 545,\n",
       " 'casting': 546,\n",
       " 'outside': 547,\n",
       " 'level': 548,\n",
       " 'spicy': 549,\n",
       " 'over': 550,\n",
       " 'fairly': 551,\n",
       " 'person': 552,\n",
       " 'plain': 553,\n",
       " 'walked': 554,\n",
       " 'ended': 555,\n",
       " 'feels': 556,\n",
       " 'rocks': 557,\n",
       " 'enjoyable': 558,\n",
       " 'etc': 559,\n",
       " 'instead': 560,\n",
       " 'moving': 561,\n",
       " 'songs': 562,\n",
       " 'later': 563,\n",
       " 'headsets': 564,\n",
       " 'wish': 565,\n",
       " 'hit': 566,\n",
       " 'space': 567,\n",
       " 'looked': 568,\n",
       " 'within': 569,\n",
       " 'dance': 570,\n",
       " 'showed': 571,\n",
       " 'wall': 572,\n",
       " 'sat': 573,\n",
       " 'leave': 574,\n",
       " 'theater': 575,\n",
       " 'internet': 576,\n",
       " 'zero': 577,\n",
       " 'sweet': 578,\n",
       " 'helpful': 579,\n",
       " 'rated': 580,\n",
       " 'color': 581,\n",
       " 'data': 582,\n",
       " 'cable': 583,\n",
       " 'drago': 584,\n",
       " 'table': 585,\n",
       " 'unless': 586,\n",
       " 'ten': 587,\n",
       " 'please': 588,\n",
       " 'third': 589,\n",
       " 'review': 590,\n",
       " 'somewhat': 591,\n",
       " 'thinking': 592,\n",
       " 'mention': 593,\n",
       " 'needs': 594,\n",
       " 'annoying': 595,\n",
       " 'memorable': 596,\n",
       " 'usual': 597,\n",
       " 'happened': 598,\n",
       " 'clever': 599,\n",
       " 'mostly': 600,\n",
       " 'premise': 601,\n",
       " 'leather': 602,\n",
       " 'cut': 603,\n",
       " 'jabra': 604,\n",
       " 'hated': 605,\n",
       " 'shot': 606,\n",
       " 'joy': 607,\n",
       " 'heart': 608,\n",
       " 'boring': 609,\n",
       " 'cingular': 610,\n",
       " 'recently': 611,\n",
       " 'poorly': 612,\n",
       " 'thats': 613,\n",
       " 'turned': 614,\n",
       " 'ice': 615,\n",
       " 'due': 616,\n",
       " 'throughout': 617,\n",
       " 'mouth': 618,\n",
       " 'minute': 619,\n",
       " 'rolls': 620,\n",
       " 'literally': 621,\n",
       " 'period': 622,\n",
       " 'rate': 623,\n",
       " 'beginning': 624,\n",
       " 'pull': 625,\n",
       " 'ray': 626,\n",
       " 'charles': 627,\n",
       " 'lame': 628,\n",
       " 'bother': 629,\n",
       " 'thriller': 630,\n",
       " 'lost': 631,\n",
       " 'comes': 632,\n",
       " 'pg': 633,\n",
       " 'production': 634,\n",
       " 'easier': 635,\n",
       " 'clarity': 636,\n",
       " 'crowd': 637,\n",
       " 'mickey': 638,\n",
       " 'favorite': 639,\n",
       " 'pho': 640,\n",
       " 'asked': 641,\n",
       " 'station': 642,\n",
       " 'previous': 643,\n",
       " 'touch': 644,\n",
       " 'shipping': 645,\n",
       " 'seeing': 646,\n",
       " 'ups': 647,\n",
       " 'turns': 648,\n",
       " 'blue': 649,\n",
       " 'seem': 650,\n",
       " 'serious': 651,\n",
       " 'total': 652,\n",
       " 'useless': 653,\n",
       " 'often': 654,\n",
       " 'guy': 655,\n",
       " 'seafood': 656,\n",
       " 'nasty': 657,\n",
       " 'steaks': 658,\n",
       " 'nokia': 659,\n",
       " 'living': 660,\n",
       " 'indeed': 661,\n",
       " 'amount': 662,\n",
       " 'original': 663,\n",
       " 'waiter': 664,\n",
       " 'fall': 665,\n",
       " 'large': 666,\n",
       " 'empty': 667,\n",
       " 'thin': 668,\n",
       " 'fear': 669,\n",
       " 'anyway': 670,\n",
       " 'understand': 671,\n",
       " 'entertaining': 672,\n",
       " 'course': 673,\n",
       " 'particular': 674,\n",
       " 'cant': 675,\n",
       " 'hand': 676,\n",
       " 'cult': 677,\n",
       " 'classic': 678,\n",
       " 'ability': 679,\n",
       " 'earlier': 680,\n",
       " 'graphics': 681,\n",
       " 'damn': 682,\n",
       " 'decision': 683,\n",
       " 'wings': 684,\n",
       " 'appearance': 685,\n",
       " 'others': 686,\n",
       " 'fries': 687,\n",
       " 'rare': 688,\n",
       " 'scamp': 689,\n",
       " 'provided': 690,\n",
       " 'yes': 691,\n",
       " 'clean': 692,\n",
       " 'five': 693,\n",
       " 'phoenix': 694,\n",
       " 'gone': 695,\n",
       " 'consider': 696,\n",
       " 'date': 697,\n",
       " 'quiet': 698,\n",
       " 'trouble': 699,\n",
       " 'saying': 700,\n",
       " 'direction': 701,\n",
       " 'dinner': 702,\n",
       " 'convenient': 703,\n",
       " 'stanwyck': 704,\n",
       " 'ways': 705,\n",
       " 'child': 706,\n",
       " 'share': 707,\n",
       " 'idea': 708,\n",
       " 'vegetables': 709,\n",
       " 'thai': 710,\n",
       " 'stereotypes': 711,\n",
       " 'edge': 712,\n",
       " 'cover': 713,\n",
       " 'final': 714,\n",
       " 'sub': 715,\n",
       " 'effort': 716,\n",
       " 'business': 717,\n",
       " 'bottom': 718,\n",
       " 'send': 719,\n",
       " 'wine': 720,\n",
       " '12': 721,\n",
       " 'included': 722,\n",
       " 'drinks': 723,\n",
       " 'scratched': 724,\n",
       " 'form': 725,\n",
       " 'games': 726,\n",
       " 'neither': 727,\n",
       " 'feet': 728,\n",
       " 'drain': 729,\n",
       " 'options': 730,\n",
       " 'god': 731,\n",
       " 'connection': 732,\n",
       " 'trip': 733,\n",
       " 'actress': 734,\n",
       " 'racial': 735,\n",
       " 'honest': 736,\n",
       " 'struck': 737,\n",
       " 'brain': 738,\n",
       " 'all': 739,\n",
       " 'machine': 740,\n",
       " 'journey': 741,\n",
       " 'boyfriend': 742,\n",
       " 'nut': 743,\n",
       " 'sounds': 744,\n",
       " 'potatoes': 745,\n",
       " '\\x96': 746,\n",
       " 'rent': 747,\n",
       " 'beat': 748,\n",
       " 'stuff': 749,\n",
       " 'sturdy': 750,\n",
       " 'beans': 751,\n",
       " 'age': 752,\n",
       " 'brunch': 753,\n",
       " 'scenery': 754,\n",
       " 'cute': 755,\n",
       " 'busy': 756,\n",
       " 'stage': 757,\n",
       " 'plays': 758,\n",
       " 'holds': 759,\n",
       " 'complete': 760,\n",
       " 'attention': 761,\n",
       " 'sprint': 762,\n",
       " 'smart': 763,\n",
       " 'charged': 764,\n",
       " 'breaks': 765,\n",
       " 'pair': 766,\n",
       " 'knew': 767,\n",
       " 'actor': 768,\n",
       " 'talented': 769,\n",
       " 'owners': 770,\n",
       " 'disgusting': 771,\n",
       " 'dining': 772,\n",
       " 'ladies': 773,\n",
       " 'vibe': 774,\n",
       " 'portions': 775,\n",
       " 'fry': 776,\n",
       " 'interest': 777,\n",
       " 'paced': 778,\n",
       " 'nearly': 779,\n",
       " 'video': 780,\n",
       " 'mobile': 781,\n",
       " 'words': 782,\n",
       " 'potato': 783,\n",
       " 'hair': 784,\n",
       " 'score': 785,\n",
       " 'fabulous': 786,\n",
       " 'crisp': 787,\n",
       " 'added': 788,\n",
       " 'bill': 789,\n",
       " 'tip': 790,\n",
       " 'noise': 791,\n",
       " 'starts': 792,\n",
       " 'describe': 793,\n",
       " 'billy': 794,\n",
       " 'attempt': 795,\n",
       " 'exactly': 796,\n",
       " 'constructed': 797,\n",
       " 'results': 798,\n",
       " 'reviews': 799,\n",
       " 'likes': 800,\n",
       " 'advise': 801,\n",
       " 'regular': 802,\n",
       " 'bread': 803,\n",
       " 'stop': 804,\n",
       " 'embarrassing': 805,\n",
       " 'thrown': 806,\n",
       " 'reason': 807,\n",
       " 'ruthless': 808,\n",
       " 'killer': 809,\n",
       " 'down': 810,\n",
       " 'self': 811,\n",
       " 'wooden': 812,\n",
       " 'tables': 813,\n",
       " 'folks': 814,\n",
       " 'sorry': 815,\n",
       " 'lacking': 816,\n",
       " 'tries': 817,\n",
       " 'considering': 818,\n",
       " 'father': 819,\n",
       " 'italian': 820,\n",
       " 'reviewer': 821,\n",
       " 'daughter': 822,\n",
       " 'drive': 823,\n",
       " 'parts': 824,\n",
       " 'women': 825,\n",
       " 'martin': 826,\n",
       " 'despite': 827,\n",
       " 'chargers': 828,\n",
       " 'tinny': 829,\n",
       " 'bacon': 830,\n",
       " 'plantronics': 831,\n",
       " 'issues': 832,\n",
       " 'friend': 833,\n",
       " 'making': 834,\n",
       " 'duck': 835,\n",
       " 'oscar': 836,\n",
       " 'ease': 837,\n",
       " 'involved': 838,\n",
       " 'computer': 839,\n",
       " 'tacos': 840,\n",
       " 'scary': 841,\n",
       " 'clip': 842,\n",
       " 'towards': 843,\n",
       " 'write': 844,\n",
       " 'dessert': 845,\n",
       " 'ambiance': 846,\n",
       " 'scale': 847,\n",
       " 'greek': 848,\n",
       " 'flavorful': 849,\n",
       " 'ranks': 850,\n",
       " 'lacked': 851,\n",
       " 'dry': 852,\n",
       " 'garbage': 853,\n",
       " 'im': 854,\n",
       " 'wind': 855,\n",
       " 'seller': 856,\n",
       " 'realized': 857,\n",
       " 'visual': 858,\n",
       " 'genuine': 859,\n",
       " 'industry': 860,\n",
       " '40': 861,\n",
       " 'bucks': 862,\n",
       " 'clearly': 863,\n",
       " 'ready': 864,\n",
       " 'worthless': 865,\n",
       " 'holes': 866,\n",
       " 'dvd': 867,\n",
       " 'storyline': 868,\n",
       " 'contained': 869,\n",
       " 'dancing': 870,\n",
       " 'keyboard': 871,\n",
       " 'number': 872,\n",
       " 'experienced': 873,\n",
       " 'effective': 874,\n",
       " 'mistake': 875,\n",
       " 'anytime': 876,\n",
       " 'brought': 877,\n",
       " 'seconds': 878,\n",
       " 'singing': 879,\n",
       " 'delivers': 880,\n",
       " 'hoping': 881,\n",
       " 'trilogy': 882,\n",
       " 'glasses': 883,\n",
       " 'salsa': 884,\n",
       " 'thoroughly': 885,\n",
       " 'paid': 886,\n",
       " 'clichés': 887,\n",
       " 'scared': 888,\n",
       " 'wasting': 889,\n",
       " 'actresses': 890,\n",
       " 'opened': 891,\n",
       " '13': 892,\n",
       " 'flaws': 893,\n",
       " 'immediately': 894,\n",
       " 'occasionally': 895,\n",
       " 'vegetarian': 896,\n",
       " 'pasta': 897,\n",
       " 'steve': 898,\n",
       " 'chinese': 899,\n",
       " 'goes': 900,\n",
       " 'released': 901,\n",
       " 'values': 902,\n",
       " 'q': 903,\n",
       " 'sounded': 904,\n",
       " 'charming': 905,\n",
       " 'energy': 906,\n",
       " 'presents': 907,\n",
       " 'lovely': 908,\n",
       " 'tremendous': 909,\n",
       " 'material': 910,\n",
       " 'says': 911,\n",
       " 'boy': 912,\n",
       " 'plugged': 913,\n",
       " 'flip': 914,\n",
       " 'ripped': 915,\n",
       " 'eaten': 916,\n",
       " 'bunch': 917,\n",
       " 'pretentious': 918,\n",
       " 'elsewhere': 919,\n",
       " 'crazy': 920,\n",
       " 'james': 921,\n",
       " 'break': 922,\n",
       " 'lightweight': 923,\n",
       " 'chips': 924,\n",
       " 'bargain': 925,\n",
       " 'incredibly': 926,\n",
       " 'wise': 927,\n",
       " 'speak': 928,\n",
       " 'wonderfully': 929,\n",
       " 'wow': 930,\n",
       " 'narrative': 931,\n",
       " 'dirty': 932,\n",
       " 'spend': 933,\n",
       " 'trash': 934,\n",
       " 'tale': 935,\n",
       " 'heard': 936,\n",
       " 'cost': 937,\n",
       " '7': 938,\n",
       " 'huston': 939,\n",
       " 'visit': 940,\n",
       " 'salmon': 941,\n",
       " 'follow': 942,\n",
       " 'south': 943,\n",
       " 'photography': 944,\n",
       " 'restaurants': 945,\n",
       " 'directed': 946,\n",
       " 'bored': 947,\n",
       " 'puppets': 948,\n",
       " 'tea': 949,\n",
       " 'lg': 950,\n",
       " 'cream': 951,\n",
       " 'angel': 952,\n",
       " 'silent': 953,\n",
       " 'impressive': 954,\n",
       " 'particularly': 955,\n",
       " 'sending': 956,\n",
       " 'owned': 957,\n",
       " 'returning': 958,\n",
       " 'single': 959,\n",
       " 'changing': 960,\n",
       " 'drink': 961,\n",
       " 'moist': 962,\n",
       " 'fish': 963,\n",
       " 'son': 964,\n",
       " 'loves': 965,\n",
       " 'definately': 966,\n",
       " 'double': 967,\n",
       " 'serving': 968,\n",
       " 'toasted': 969,\n",
       " 'english': 970,\n",
       " 'texture': 971,\n",
       " 'convincing': 972,\n",
       " 'meh': 973,\n",
       " 'passed': 974,\n",
       " 'atrocious': 975,\n",
       " 'sad': 976,\n",
       " 'created': 977,\n",
       " 'disliked': 978,\n",
       " 'christmas': 979,\n",
       " 'timely': 980,\n",
       " 'culture': 981,\n",
       " 'disturbing': 982,\n",
       " 'judge': 983,\n",
       " '90': 984,\n",
       " 'example': 985,\n",
       " 'nobody': 986,\n",
       " 'predictably': 987,\n",
       " 'torture': 988,\n",
       " 'based': 989,\n",
       " 'uncomfortable': 990,\n",
       " 'be': 991,\n",
       " 'obvious': 992,\n",
       " 'odd': 993,\n",
       " 'peter': 994,\n",
       " 'bt': 995,\n",
       " 'sentiment': 996,\n",
       " 'highest': 997,\n",
       " 'imaginable': 998,\n",
       " 'called': 999,\n",
       " 'shots': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words= 5000, lower= False)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f\"Vocab is {vocab_size} elements long.\")\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "81b450ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seqs = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_pad = pad_sequences(X_train_seqs, maxlen=max_review_length, padding='post')\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_review_length, padding='post')\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_valid)\n",
    "X_val_pad = pad_sequences(X_val_seq, maxlen=max_review_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "753e103a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the padded reviews within the training set is (2100, 41)\n",
      "[[1607  113  191 ...    0    0    0]\n",
      " [ 328 1609  693 ...    0    0    0]\n",
      " [   8  374  694 ...    0    0    0]\n",
      " ...\n",
      " [ 427  131    0 ...    0    0    0]\n",
      " [ 173  266   30 ...    0    0    0]\n",
      " [ 198  150  180 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"The shape of the padded reviews within the training set is {X_train_pad.shape}\")\n",
    "print(X_train_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "214bd428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the padded reviews within the training set is (2100,)\n",
      "520     0\n",
      "2152    0\n",
      "2766    1\n",
      "2752    1\n",
      "2827    0\n",
      "       ..\n",
      "1606    1\n",
      "746     1\n",
      "1955    0\n",
      "2574    1\n",
      "1516    1\n",
      "Name: recommended, Length: 2100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"The shape of the padded reviews within the training set is {y_train.shape}\")\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e2a40a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('task2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "548bbfda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,773,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_15 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m4096\u001b[0m)       │    \u001b[38;5;34m16,773,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │       \u001b[38;5;34m262,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,037,441</span> (64.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,037,441\u001b[0m (64.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,037,441</span> (64.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,037,441\u001b[0m (64.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=[41]))\n",
    "model.add(Embedding(input_dim= vocab_size, output_dim= 4096, input_length = max_review_length))\n",
    "model.add(Dense(64, activation = \"relu\"))\n",
    "model.add(Dense(32, activation = \"relu\"))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "83f4aab5",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 44.2 GiB for an array with shape (144734100, 41) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[153]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m num_classes = \u001b[32m41\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m y_train = \u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(y_train.shape)\n\u001b[32m      4\u001b[39m early_stop_check = EarlyStopping(monitor= \u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m3\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hsgam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\numerical_utils.py:98\u001b[39m, in \u001b[36mto_categorical\u001b[39m\u001b[34m(x, num_classes)\u001b[39m\n\u001b[32m     96\u001b[39m     num_classes = np.max(x) + \u001b[32m1\u001b[39m\n\u001b[32m     97\u001b[39m batch_size = x.shape[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m categorical = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m categorical[np.arange(batch_size), x] = \u001b[32m1\u001b[39m\n\u001b[32m    100\u001b[39m output_shape = input_shape + (num_classes,)\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 44.2 GiB for an array with shape (144734100, 41) and data type float64"
     ]
    }
   ],
   "source": [
    "num_classes = 41\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "print(y_train.shape)\n",
    "early_stop_check = EarlyStopping(monitor= 'val_accuracy', patience=3)\n",
    "results = model.fit(X_train_pad, y_train, epochs=15, callbacks=early_stop_check)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
